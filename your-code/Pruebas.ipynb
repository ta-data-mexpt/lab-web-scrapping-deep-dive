{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c17839-8869-4aa0-ab60-9483e927fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa8a06e-c092-4438-83c5-97856413c90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "r1 = requests.get('https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/documents/the-html5-breakfast-site.html')\n",
    "print(r1.status_code)\n",
    "\n",
    "\"\"\"\n",
    "Qué es status code 200?\n",
    "Tranquilo, si de repente ves el aviso en tu ordenador \n",
    "de status code 200 no pasa nada. Todo está bien.\n",
    "\n",
    "El status code 200 es un código de estado que nos dice que la petición que \n",
    "acabamos de hacer ha sido entendida, enviada y recibida.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ec0b57-8ba8-47b1-8b51-53dfd86b0508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    }
   ],
   "source": [
    "r2 = requests.get('https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/documents/forbidden')\n",
    "print(r2.status_code)\n",
    "\n",
    "\"\"\"\n",
    "Códigos de estado 4XX\n",
    "Como ya te indicamos antes, las notificaciones que reenvía el servidor y que son fallos son los códigos 4XX, \n",
    "es decir, un cuatro acompañado de otros dos números.\n",
    "\n",
    "Los códigos 4XX nos quieren decir que son errores del cliente. Es decir, es fallo de la página que estamos intentando consultar.\n",
    "\n",
    "Lo normal en este tipo de notificaciones es que se nos impida el acceso a la página web a través del código 403, que suele denegar el acceso al sitio web que estamos intentando entrar.\n",
    "\n",
    "Otro error común y parecido al 403 es el 404 y no es otra cosa que la página que hemos intentado cargar no ha sido localizada.\n",
    "\n",
    "Una posible solución es intentar escribir de nuevo la dirección o URL, ya que igual la hemos puesto mal.\n",
    "\n",
    "También puede suceder que la página ya no esté disponible y no exista. En todo caso, y a menos que seamos los dueños de la página, poco más podemos hacer.\n",
    "\n",
    "Al margen de los errores 403 y 404, hay tres códigos de estado más: el 400, el 401 y el 406.\n",
    "\n",
    "\n",
    "Códigos de estado 5XX\n",
    "Existe otra clase de errores y son los 5XX. A diferencia de los códigos 4XX, los 5XX no son del cliente; es decir,\n",
    "de la página, y sí son del servidor.\n",
    "\n",
    "Uno de los errores más comunes dentro de los 5XX es el 500. El código de estado 500 es un error interno del código de la página.\n",
    "\n",
    "Este es un problema gordo para los dueños de sitios web y un fallo común que la mayoría de los usuarios avanzados \n",
    "de CMS como WordPress han visto alguna vez.\n",
    "\n",
    "Si eres dueño de la página que tiene este error, te aconsejamos que consultes al servicio técnico del hosting \n",
    "para que te ayuden con el problema.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f594f67-3359-4c8f-8893-1e31a12b5808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Response [301]>]\n"
     ]
    }
   ],
   "source": [
    "r3 = requests.get('http://google.com')\n",
    "print(r3.history)\n",
    "\n",
    "\"\"\"\n",
    "301 Movido Permanentemente\n",
    "El código de respuesta de estado de redirección del Protocolo de transferencia de \n",
    "hipertexto (HTTP) 301 Moved Permanentlyindica que el recurso solicitado se ha movido definitivamente \n",
    "a la URL proporcionada por los Locationencabezados. Un navegador redirige a la nueva URL y los motores de búsqueda \n",
    "actualizan sus enlaces al recurso.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be221904-e3e2-44b2-a05a-7494803a9116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n"
     ]
    }
   ],
   "source": [
    "print(r3.history[0].status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc93419-2f47-43db-b1b5-ff08383a78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML><HEAD><meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\">\n",
      "<TITLE>301 Moved</TITLE></HEAD><BODY>\n",
      "<H1>301 Moved</H1>\n",
      "The document has moved\n",
      "<A HREF=\"http://www.google.com/\">here</A>.\n",
      "</BODY></HTML>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(r3.history[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416865ef-fc02-4988-8678-60da3497a773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c2b35fd-617a-4103-ad00-9cdf1019e22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request was successful\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url='http://google.com'\n",
    "\n",
    "r = requests.get(url) \n",
    "if r.status_code < 300:\n",
    "    print('request was successful')\n",
    "elif r.status_code >= 400 and r.status_code < 500:\n",
    "    print('request failed because the resource either does not exist or is forbidden')\n",
    "else:\n",
    "    print('request failed because the response server encountered an error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca799ee1-d928-4d5b-a32a-2907dfa32885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "288adfc9-1e87-428d-9696-fe7151944e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    r = requests.get(url, timeout=10)\n",
    "except requests.exceptions.Timeout:\n",
    "    print ('a')\n",
    "    # timeout error... do something\n",
    "#except requests.exceptions.TooManyRedirects:\n",
    "    # redirect error... do something\n",
    "#except requests.exceptions.SSLError:\n",
    "    # ssl error... do something\n",
    "#except requests.exceptions.RequestException as e:\n",
    "    # other unknown errors... do something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb75e3-ac1e-41d6-8de6-8270695c9dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc9eddcb-0c7a-4fe1-a7f1-344886bf82c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"es-419\"><head><meta charset=\"UTF-8\"><meta content=\"origin\" name=\"referrer\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><link href=\"/manifest?pwa=webhp\" crossorigin=\"use-credentials\" rel=\"manifest\"><title>Google</title><script nonce=\"Q2HXARtxipeiNvVbzZgLSw\">(function(){window.google={kEI:\\'Wbx7Y9_jF9fNkPIP-eqiqAM\\',kEXPI:\\'31\\',kBL:\\'dQwl\\'};google.sn=\\'webhp\\';google.kHL=\\'es-419\\';})();(function(){\\nvar f=this||self;var h,k=[];function l(a){for(var b;a&&(!a.getAttribute||!(b=a.g'\n"
     ]
    }
   ],
   "source": [
    "url='http://google.com'\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'}\n",
    "response = requests.get(url, headers=headers)\n",
    "print(response.content[0:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9064b251-178b-4898-92b3-454c1ebad44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting asyncio\n",
      "  Downloading asyncio-3.4.3-py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 912 kB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: asyncio\n",
      "Successfully installed asyncio-3.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fee5acb-1c0b-45ef-bba3-96f76d5a2b33",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[1;32m     15\u001b[0m loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[0;32m---> 16\u001b[0m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/asyncio/base_events.py:623\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m--> 623\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[1;32m    626\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/asyncio/base_events.py:583\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_running\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m--> 583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    586\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "import asyncio, requests\n",
    "\n",
    "urls = [\n",
    "    'https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/documents/breakfast.jpg',\n",
    "    'https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/documents/forbidden',\n",
    "    'https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/documents/the-html5-breakfast-site.html'\n",
    "]\n",
    "\n",
    "async def main():\n",
    "    loop = asyncio.get_event_loop()\n",
    "    futures = [loop.run_in_executor(None, requests.get, url) for url in urls]\n",
    "    for response in await asyncio.gather(*futures):\n",
    "        print(response.status_code)\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3adc61-21e5-43f3-beaa-6f44857fc3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb7486-f4bd-410d-a1a8-ea5a81fdf776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57062bea-4b66-403e-8bcd-c14a18283125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "403\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests, time\n",
    "\n",
    "urls = [\n",
    "    'https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/documents/breakfast.jpg',\n",
    "    'https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/documents/forbidden',\n",
    "    'https://s3-eu-west-1.amazonaws.com/ih-materials/uploads/data-static/documents/the-html5-breakfast-site.html'\n",
    "]\n",
    "\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    print(response.status_code)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06a916-3cba-47c6-a105-473ca8f502cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "47d5e4eb-3336-49df-8792-7c4cc933c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "     Esta es la clase de constructor a la que puede pasar un montón de parámetros.\n",
    "     Estos parámetros se almacenan en las variables de instancia de clase para que el\n",
    "     las funciones de clase pueden acceder a ellas más tarde.\n",
    "    \n",
    "     url_pattern: el patrón de expresiones regulares de las URL web para escapar\n",
    "     pages_to_scrape: cuántas páginas raspar\n",
    "     sleep_interval: el intervalo de tiempo en segundos para retrasar entre solicitudes. Si <0, las solicitudes no se retrasarán.\n",
    "     content_parser: una referencia de función que extraerá la información deseada del contenido raspado.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "     Scrape el contenido de una sola url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "     Exporte el contenido raspado. En este momento simplemente imprime los resultados.\n",
    "     Pero en el futuro puede exportar los resultados a un archivo de texto o base de datos.\n",
    "     \"\"\"\n",
    "    \n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "     Después de instanciar la clase, llame a esta función para iniciar los trabajos de raspado.\n",
    "     Esta función usa un bucle FOR para llamar a `scrape_url()` para cada url a raspar.\n",
    "     \"\"\"\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Esta es una función de analizador personalizado que completará en el desafío.\n",
    "En este momento, simplemente devuelve la cadena que se le pasó. Pero en este laboratorio\n",
    "completarás esta función para que extraiga las comillas.\n",
    "Esta función se pasará a la clase IronhackSpider.\n",
    "\"\"\"\n",
    "\n",
    "def quotes_parser(content):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    sopa_git = BeautifulSoup(content)\n",
    "    bloques = sopa_git.select('div.quote')\n",
    "    respuesta=[]\n",
    "    for item in bloques:\n",
    "        respuesta.append(item.text.replace('\\n',' '))\n",
    "    return respuesta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4ae94e7a-0105-486e-b426-96d9283a2826",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 1 # how many webpages to scrapge\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e3b3bdff-33cd-45f3-91cf-22aa34e45155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f4565012-00f8-4463-94e7-cf8347dd22f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.” by Albert Einstein (about)               Tags:              change deep-thoughts thinking world  ', ' “It is our choices, Harry, that show what we truly are, far more than our abilities.” by J.K. Rowling (about)               Tags:              abilities choices  ', ' “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.” by Albert Einstein (about)               Tags:              inspirational life live miracle miracles  ', ' “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.” by Jane Austen (about)               Tags:              aliteracy books classic humor  ', \" “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.” by Marilyn Monroe (about)               Tags:              be-yourself inspirational  \", ' “Try not to become a man of success. Rather become a man of value.” by Albert Einstein (about)               Tags:              adulthood success value  ', ' “It is better to be hated for what you are than to be loved for what you are not.” by André Gide (about)               Tags:              life love  ', \" “I have not failed. I've just found 10,000 ways that won't work.” by Thomas A. Edison (about)               Tags:              edison failure inspirational paraphrased  \", \" “A woman is like a tea bag; you never know how strong it is until it's in hot water.” by Eleanor Roosevelt (about)               Tags:              misattributed-eleanor-roosevelt  \", ' “A day without sunshine is like, you know, night.” by Steve Martin (about)               Tags:              humor obvious simile  ']\n"
     ]
    }
   ],
   "source": [
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62203153-0f2d-41e1-9b49-364a55ad4037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8ee10-40ad-45bb-9f75-1b1b258adf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "esponse = requests.get(url)\n",
    "result = self.content_parser(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e551019-3d7f-4630-aabd-79f0518d6d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1d7f315-1e54-4282-9839-48e15d6808a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a6142feb-4f6f-42be-a282-38169ab1f044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html>\\n  <head>\\n    <title>The HTML5 Breakfast Site</title>\\n    <meta charset=\"UTF-8\">\\n\\n    <style>\\n      body {\\n        background-color: limegreen;\\n        margin: 40px;\\n      } \\n    </style>\\n  </head>\\n  <body>\\n    <div id=\"container\">\\n\\n      <nav id=\"topnav\">\\n        <a href=\"https://www.ironhack.com\" target=\"_blank\">HOME</a> |\\n        <a href=\"https://www.ironhack.com/en/team\" target=\"_blank\">ABOUT US</a> |\\n        <a href=\"https://www.ironhack.com/en/contact\" target=\"_blank\">CONTACT US</a>\\n      </nav>\\n\\n      <section id=\"content\">\\n        <h1>The Ironhack Breakfast Place</h1>\\n        <p>Here you will find all sorts of delicious treats</p>\\n        <figure>\\n          <img src=\"breakfast.jpg\" width=\"400\" alt=\"healthy breakfast\">\\n          <figcaption>CC Image courtesy of Ruth Hartnup on Flickr</figcaption>\\n        </figure>\\n      </section>\\n\\n      <footer>\\n        <p class=\"love\">Made with love by Ironhack</p>\\n      </footer>\\n\\n    </div>\\n  </body>\\n</html>\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e87e51-94b9-457c-8777-cf075927f0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f253fbde-d75f-46a1-a50a-550689c96f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f472061-30f1-4aea-beec-c5d2d9777165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sopa_git = BeautifulSoup(response.content)\n",
    "#bloques = sopa_git.select('article.Box-row.d-flex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6d2ed083-0637-47f1-9306-685063f9b716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<title>The HTML5 Breakfast Site</title>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<style>\n",
       "      body {\n",
       "        background-color: limegreen;\n",
       "        margin: 40px;\n",
       "      } \n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "<div id=\"container\">\n",
       "<nav id=\"topnav\">\n",
       "<a href=\"https://www.ironhack.com\" target=\"_blank\">HOME</a> |\n",
       "        <a href=\"https://www.ironhack.com/en/team\" target=\"_blank\">ABOUT US</a> |\n",
       "        <a href=\"https://www.ironhack.com/en/contact\" target=\"_blank\">CONTACT US</a>\n",
       "</nav>\n",
       "<section id=\"content\">\n",
       "<h1>The Ironhack Breakfast Place</h1>\n",
       "<p>Here you will find all sorts of delicious treats</p>\n",
       "<figure>\n",
       "<img alt=\"healthy breakfast\" src=\"breakfast.jpg\" width=\"400\"/>\n",
       "<figcaption>CC Image courtesy of Ruth Hartnup on Flickr</figcaption>\n",
       "</figure>\n",
       "</section>\n",
       "<footer>\n",
       "<p class=\"love\">Made with love by Ironhack</p>\n",
       "</footer>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sopa_git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b97cf47-4712-46e3-a591-f8578cf1016d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  The HTML5 Breakfast Site       HOME |         ABOUT US |         CONTACT US   The Ironhack Breakfast Place Here you will find all sorts of delicious treats   CC Image courtesy of Ruth Hartnup on Flickr    Made with love by Ironhack     '"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sopa_git.text.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "05d28fa0-7e0b-4623-93ea-f068d8888034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Ironhack Breakfast Place Here you will find all sorts of delicious treats   CC Image courtesy of Ruth Hartnup on Flickr  '"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sopa_git.select('section')[0].text.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b1cf18-317e-4a66-abbb-76c3ce115cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed81538-f60a-4ba1-a84c-b30a4c7d34b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IronhackSpider.scrape_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "629dd0d2-df69-4107-852a-5f22b7f6c778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request failed because the response server encountered an error\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/'\n",
    "url='http://quotes.toscrape.com/page/%s/'\n",
    "\n",
    "r = requests.get(url) \n",
    "if r.status_code < 300:\n",
    "    print('request was successful')\n",
    "elif r.status_code >= 400 and r.status_code < 500:\n",
    "    print('request failed because the resource either does not exist or is forbidden')\n",
    "else:\n",
    "    print('request failed because the response server encountered an error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0f5e656b-3ebc-486c-aa3a-0b7e40741a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bien\n"
     ]
    }
   ],
   "source": [
    "url='http://quotes.toscrape.com/page/%s/'\n",
    "\n",
    "try:\n",
    "    r = requests.get(url, timeout=10)\n",
    "    print('bien')\n",
    "except requests.exceptions.Timeout:\n",
    "    print ('TIMEOUT')\n",
    "    # timeout error... do something\n",
    "\n",
    "except requests.exceptions.TooManyRedirects:\n",
    "    print ('MANY REDIRECTS')\n",
    "    # redirect error... do something\n",
    "except requests.exceptions.SSLError:\n",
    "    print ('SSL ERROR')\n",
    "    # ssl error... do something\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print ('REQUESTS EXCEPTION')\n",
    "    # other unknown errors... do something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7a451609-fcf9-4ebf-96af-e7af5d5d3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "     Esta es la clase de constructor a la que puede pasar un montón de parámetros.\n",
    "     Estos parámetros se almacenan en las variables de instancia de clase para que el\n",
    "     las funciones de clase pueden acceder a ellas más tarde.\n",
    "    \n",
    "     url_pattern: el patrón de expresiones regulares de las URL web para escapar\n",
    "     pages_to_scrape: cuántas páginas raspar\n",
    "     sleep_interval: el intervalo de tiempo en segundos para retrasar entre solicitudes. Si <0, las solicitudes no se retrasarán.\n",
    "     content_parser: una referencia de función que extraerá la información deseada del contenido raspado.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "     Scrape el contenido de una sola url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            \n",
    "            if response.status_code < 300:\n",
    "                print('request was successful \\n')\n",
    "            elif response.status_code >= 400 and r.status_code < 500:\n",
    "                print('request failed because the resource either does not exist or is forbidden \\n')\n",
    "            else:\n",
    "                print('request failed because the response server encountered an error \\n')\n",
    "                \n",
    "            result = self.content_parser(response.content)\n",
    "            self.output_results(result)\n",
    "            \n",
    "        except requests.exceptions.Timeout:\n",
    "            print ('TIMEOUT')\n",
    "            # timeout error... do something\n",
    "        except requests.exceptions.TooManyRedirects:\n",
    "            print ('MANY REDIRECTS')\n",
    "            # redirect error... do something\n",
    "        except requests.exceptions.SSLError:\n",
    "            print ('SSL ERROR')\n",
    "            # ssl error... do something\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print ('REQUESTS EXCEPTION')\n",
    "            # other unknown errors... do something\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "     Exporte el contenido raspado. En este momento simplemente imprime los resultados.\n",
    "     Pero en el futuro puede exportar los resultados a un archivo de texto o base de datos.\n",
    "     \"\"\"\n",
    "    \n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "     Después de instanciar la clase, llame a esta función para iniciar los trabajos de raspado.\n",
    "     Esta función usa un bucle FOR para llamar a `scrape_url()` para cada url a raspar.\n",
    "     \"\"\"\n",
    "    def kickstart(self):\n",
    "        import time\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "            if self.sleep_interval > 0:\n",
    "                print('\\nSLEEP INTERVAL \\n')\n",
    "                time.sleep(1)\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Esta es una función de analizador personalizado que completará en el desafío.\n",
    "En este momento, simplemente devuelve la cadena que se le pasó. Pero en este laboratorio\n",
    "completarás esta función para que extraiga las comillas.\n",
    "Esta función se pasará a la clase IronhackSpider.\n",
    "\"\"\"\n",
    "\n",
    "def quotes_parser(content):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    sopa_git = BeautifulSoup(content)\n",
    "    bloques = sopa_git.select('div.quote')\n",
    "    respuesta=[]\n",
    "    for item in bloques:\n",
    "        respuesta.append(item.text.replace('\\n',' '))\n",
    "    return respuesta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d4fcc167-3da5-4282-877f-be178ebb2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 2 # how many webpages to scrapge\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE,  sleep_interval=1, content_parser=quotes_parser)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e0e60dc8-b50c-4de5-a372-3e5ec2823378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request was successful \n",
      "\n",
      "[' “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.” by Albert Einstein (about)               Tags:              change deep-thoughts thinking world  ', ' “It is our choices, Harry, that show what we truly are, far more than our abilities.” by J.K. Rowling (about)               Tags:              abilities choices  ', ' “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.” by Albert Einstein (about)               Tags:              inspirational life live miracle miracles  ', ' “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.” by Jane Austen (about)               Tags:              aliteracy books classic humor  ', \" “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.” by Marilyn Monroe (about)               Tags:              be-yourself inspirational  \", ' “Try not to become a man of success. Rather become a man of value.” by Albert Einstein (about)               Tags:              adulthood success value  ', ' “It is better to be hated for what you are than to be loved for what you are not.” by André Gide (about)               Tags:              life love  ', \" “I have not failed. I've just found 10,000 ways that won't work.” by Thomas A. Edison (about)               Tags:              edison failure inspirational paraphrased  \", \" “A woman is like a tea bag; you never know how strong it is until it's in hot water.” by Eleanor Roosevelt (about)               Tags:              misattributed-eleanor-roosevelt  \", ' “A day without sunshine is like, you know, night.” by Steve Martin (about)               Tags:              humor obvious simile  ']\n",
      "\n",
      "SLEEP INTERVAL \n",
      "\n",
      "request was successful \n",
      "\n",
      "[\" “This life is what you make it. No matter what, you're going to mess up sometimes, it's a universal truth. But the good part is you get to decide how you're going to mess it up. Girls will be your friends - they'll act like it anyway. But just remember, some come, some go. The ones that stay with you through everything - they're your true best friends. Don't let go of them. Also remember, sisters make the best friends in the world. As for lovers, well, they'll come and go too. And baby, I hate to say it, most of them - actually pretty much all of them are going to break your heart, but you can't give up because if you give up, you'll never find your soulmate. You'll never find that half who makes you whole and that goes for everything. Just because you fail once, doesn't mean you're gonna fail at everything. Keep trying, hold on, and always, always, always believe in yourself, because if you don't, then who will, sweetie? So keep your head high, keep your chin up, and most importantly, keep smiling, because life's a beautiful thing and there's so much to smile about.” by Marilyn Monroe (about)               Tags:              friends heartbreak inspirational life love sisters  \", ' “It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends.” by J.K. Rowling (about)               Tags:              courage friends  ', \" “If you can't explain it to a six year old, you don't understand it yourself.” by Albert Einstein (about)               Tags:              simplicity understand  \", \" “You may not be her first, her last, or her only. She loved before she may love again. But if she loves you now, what else matters? She's not perfect—you aren't either, and the two of you may never be perfect together but if she can make you laugh, cause you to think twice, and admit to being human and making mistakes, hold onto her and give her the most you can. She may not be thinking about you every second of the day, but she will give you a part of her that she knows you can break—her heart. So don't hurt her, don't change her, don't analyze and don't expect more than she can give. Smile when she makes you happy, let her know when she makes you mad, and miss her when she's not there.” by Bob Marley (about)               Tags:              love  \", ' “I like nonsense, it wakes up the brain cells. Fantasy is a necessary ingredient in living.” by Dr. Seuss (about)               Tags:              fantasy  ', ' “I may not have gone where I intended to go, but I think I have ended up where I needed to be.” by Douglas Adams (about)               Tags:              life navigation  ', \" “The opposite of love is not hate, it's indifference. The opposite of art is not ugliness, it's indifference. The opposite of faith is not heresy, it's indifference. And the opposite of life is not death, it's indifference.” by Elie Wiesel (about)               Tags:              activism apathy hate indifference inspirational love opposite philosophy  \", ' “It is not a lack of love, but a lack of friendship that makes unhappy marriages.” by Friedrich Nietzsche (about)               Tags:              friendship lack-of-friendship lack-of-love love marriage unhappy-marriage  ', ' “Good friends, good books, and a sleepy conscience: this is the ideal life.” by Mark Twain (about)               Tags:              books contentment friends friendship life  ', ' “Life is what happens to us while we are making other plans.” by Allen Saunders (about)               Tags:              fate life misattributed-john-lennon planning plans  ']\n",
      "\n",
      "SLEEP INTERVAL \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "56c8dbe8-49d2-42e6-a977-67199dd68df4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scrape_url() missing 1 required positional argument: 'url'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [159]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmy_spider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: scrape_url() missing 1 required positional argument: 'url'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0f165c3c-cf33-4d49-9da5-c21f1c89ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 = 'http://quotes.toscrape.com/page/3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ab75e760-897f-41ed-9057-740e1ae2d126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request was successful\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(url3) \n",
    "if r.status_code < 300:\n",
    "    print('request was successful')\n",
    "elif r.status_code >= 400 and r.status_code < 500:\n",
    "    print('request failed because the resource either does not exist or is forbidden')\n",
    "else:\n",
    "    print('request failed because the response server encountered an error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c2e97ecb-72f4-424a-b2e1-cb6c9d041030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todo bien\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    r = requests.get(url3, timeout=1)\n",
    "    print('todo bien')\n",
    "except requests.exceptions.Timeout:\n",
    "    print ('TIMEOUT')\n",
    "    # timeout error... do something\n",
    "except requests.exceptions.TooManyRedirects:\n",
    "    print ('MANY REDIRECTS')\n",
    "    # redirect error... do something\n",
    "except requests.exceptions.SSLError:\n",
    "    print ('SSL ERROR')\n",
    "    # ssl error... do something\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print ('REQUESTS EXCEPTION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7295045-c9d2-40de-a98f-afc5010e8d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cfb3c1-f23b-492a-b8ab-ed3656fd7b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf0058-574e-4b37-97d6-31bbf59b99bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8f40fc06-e17a-442c-a68d-5d6ff2c6de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://books.toscrape.com/catalogue/page-1.html'\n",
    "response = requests.get(url)\n",
    "sopa_git = BeautifulSoup(response.content)\n",
    "bloques = sopa_git.select('li.col-xs-6.col-sm-4.col-md-3.col-lg-3 h3 a')\n",
    "libros=[]\n",
    "for item in bloques:\n",
    "    libros.append(item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9f00f801-6e69-4658-8576-7dbc232b0ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A Light in the ...',\n",
       " 'Tipping the Velvet',\n",
       " 'Soumission',\n",
       " 'Sharp Objects',\n",
       " 'Sapiens: A Brief History ...',\n",
       " 'The Requiem Red',\n",
       " 'The Dirty Little Secrets ...',\n",
       " 'The Coming Woman: A ...',\n",
       " 'The Boys in the ...',\n",
       " 'The Black Maria',\n",
       " 'Starving Hearts (Triangular Trade ...',\n",
       " \"Shakespeare's Sonnets\",\n",
       " 'Set Me Free',\n",
       " \"Scott Pilgrim's Precious Little ...\",\n",
       " 'Rip it Up and ...',\n",
       " 'Our Band Could Be ...',\n",
       " 'Olio',\n",
       " 'Mesaerion: The Best Science ...',\n",
       " 'Libertarianism for Beginners',\n",
       " \"It's Only the Himalayas\"]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7fae8e88-61fa-45c0-9924-da390d085481",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloques = sopa_git.select('li.col-xs-6.col-sm-4.col-md-3.col-lg-3 h3 a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3b66dc51-e2d3-436a-addb-3cda8aa7cb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bloques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e7452-bf0d-4d7c-8c20-129352e2e8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1382a862-64d0-437c-81fe-4a6a8fbd0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "     Esta es la clase de constructor a la que puede pasar un montón de parámetros.\n",
    "     Estos parámetros se almacenan en las variables de instancia de clase para que el\n",
    "     las funciones de clase pueden acceder a ellas más tarde.\n",
    "    \n",
    "     url_pattern: el patrón de expresiones regulares de las URL web para escapar\n",
    "     pages_to_scrape: cuántas páginas raspar\n",
    "     sleep_interval: el intervalo de tiempo en segundos para retrasar entre solicitudes. Si <0, las solicitudes no se retrasarán.\n",
    "     content_parser: una referencia de función que extraerá la información deseada del contenido raspado.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "     Scrape el contenido de una sola url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            \n",
    "            if response.status_code < 300:\n",
    "                print('request was successful \\n')\n",
    "            elif response.status_code >= 400 and r.status_code < 500:\n",
    "                print('request failed because the resource either does not exist or is forbidden \\n')\n",
    "            else:\n",
    "                print('request failed because the response server encountered an error \\n')\n",
    "                \n",
    "            result = self.content_parser(response.content)\n",
    "            self.output_results(result)\n",
    "            \n",
    "        except requests.exceptions.Timeout:\n",
    "            print ('TIMEOUT')\n",
    "            # timeout error... do something\n",
    "        except requests.exceptions.TooManyRedirects:\n",
    "            print ('MANY REDIRECTS')\n",
    "            # redirect error... do something\n",
    "        except requests.exceptions.SSLError:\n",
    "            print ('SSL ERROR')\n",
    "            # ssl error... do something\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print ('REQUESTS EXCEPTION')\n",
    "            # other unknown errors... do something\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "     Exporte el contenido raspado. En este momento simplemente imprime los resultados.\n",
    "     Pero en el futuro puede exportar los resultados a un archivo de texto o base de datos.\n",
    "     \"\"\"\n",
    "    \n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "     Después de instanciar la clase, llame a esta función para iniciar los trabajos de raspado.\n",
    "     Esta función usa un bucle FOR para llamar a `scrape_url()` para cada url a raspar.\n",
    "     \"\"\"\n",
    "    def kickstart(self):\n",
    "        import time\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "            if self.sleep_interval > 0:\n",
    "                print('\\nSLEEP INTERVAL \\n')\n",
    "                time.sleep(1)\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Esta es una función de analizador personalizado que completará en el desafío.\n",
    "En este momento, simplemente devuelve la cadena que se le pasó. Pero en este laboratorio\n",
    "completarás esta función para que extraiga las comillas.\n",
    "Esta función se pasará a la clase IronhackSpider.\n",
    "\"\"\"\n",
    "\n",
    "def quotes_parser(content):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    sopa_git = BeautifulSoup(content)\n",
    "    bloques = sopa_git.select('li.col-xs-6.col-sm-4.col-md-3.col-lg-3 h3 a')\n",
    "    libros=[]\n",
    "    for item in bloques:\n",
    "        libros.append(item.text)\n",
    "    return libros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "71f0db77-1330-4dff-9a16-e84014dc5f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request was successful \n",
      "\n",
      "['A Light in the ...', 'Tipping the Velvet', 'Soumission', 'Sharp Objects', 'Sapiens: A Brief History ...', 'The Requiem Red', 'The Dirty Little Secrets ...', 'The Coming Woman: A ...', 'The Boys in the ...', 'The Black Maria', 'Starving Hearts (Triangular Trade ...', \"Shakespeare's Sonnets\", 'Set Me Free', \"Scott Pilgrim's Precious Little ...\", 'Rip it Up and ...', 'Our Band Could Be ...', 'Olio', 'Mesaerion: The Best Science ...', 'Libertarianism for Beginners', \"It's Only the Himalayas\"]\n",
      "\n",
      "SLEEP INTERVAL \n",
      "\n",
      "request was successful \n",
      "\n",
      "['In Her Wake', 'How Music Works', 'Foolproof Preserving: A Guide ...', 'Chase Me (Paris Nights ...', 'Black Dust', 'Birdsong: A Story in ...', \"America's Cradle of Quarterbacks: ...\", 'Aladdin and His Wonderful ...', 'Worlds Elsewhere: Journeys Around ...', 'Wall and Piece', 'The Four Agreements: A ...', 'The Five Love Languages: ...', 'The Elephant Tree', 'The Bear and the ...', \"Sophie's World\", 'Penny Maybe', 'Maude (1883-1993):She Grew Up ...', 'In a Dark, Dark ...', 'Behind Closed Doors', \"You can't bury them ...\"]\n",
      "\n",
      "SLEEP INTERVAL \n",
      "\n",
      "request was successful \n",
      "\n",
      "['Slow States of Collapse: ...', 'Reasons to Stay Alive', 'Private Paris (Private #10)', '#HigherSelfie: Wake Up Your ...', 'Without Borders (Wanderlove #1)', 'When We Collided', 'We Love You, Charlie ...', 'Untitled Collection: Sabbath Poems ...', 'Unseen City: The Majesty ...', 'Unicorn Tracks', 'Unbound: How Eight Technologies ...', 'Tsubasa: WoRLD CHRoNiCLE 2 ...', 'Throwing Rocks at the ...', 'This One Summer', 'Thirst', 'The Torch Is Passed: ...', 'The Secret of Dreadwillow ...', 'The Pioneer Woman Cooks: ...', 'The Past Never Ends', 'The Natural History of ...']\n",
      "\n",
      "SLEEP INTERVAL \n",
      "\n"
     ]
    }
   ],
   "source": [
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "#url = 'http://books.toscrape.com/catalogue/page-1.html'\n",
    "#rl = 'http://books.toscrape.com/catalogue/page-%s.html'\n",
    "\n",
    "URL_PATTERN = 'http://books.toscrape.com/catalogue/page-%s.html' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 3 # how many webpages to scrapge\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE,  sleep_interval=1, content_parser=quotes_parser)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c99ba-966a-47fe-855e-ca1948a24b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d8b4a-6ddd-4af7-a152-a89254498806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d6c04151-0779-4920-977f-f30e3e338a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_random_ua():\n",
    "    random_ua = ''\n",
    "    ua_file = 'agents.txt'\n",
    "    try:\n",
    "        with open(ua_file) as f:\n",
    "            lines = f.readlines()\n",
    "        if len(lines) > 0:\n",
    "            prng = np.random.RandomState()\n",
    "            index = prng.permutation(len(lines) - 1)\n",
    "            idx = np.asarray(index, dtype=np.integer)[0]\n",
    "            random_ua = lines[int(idx)]\n",
    "    except Exception as ex:\n",
    "        print('Exception in random_ua')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return random_ua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "752130cd-475c-4827-9653-7164ec58a7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c0/ffsv0l194g90gxqj1nlsmvdw0000gn/T/ipykernel_22436/188913630.py:12: DeprecationWarning: Converting `np.integer` or `np.signedinteger` to a dtype is deprecated. The current result is `np.dtype(np.int_)` which is not strictly correct. Note that the result depends on the system. To ensure stable results use may want to use `np.int64` or `np.int32`.\n",
      "  idx = np.asarray(index, dtype=np.integer)[0]\n"
     ]
    }
   ],
   "source": [
    "user_agent = get_random_ua()\n",
    "user_agent = user_agent.strip('\\n')\n",
    "headers = {'user-agent': user_agent}\n",
    "r = requests.get('http://books.toscrape.com/catalogue/page-1.html',headers=headers, timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "85c53a8b-8274-4ac2-83c6-ea9769ae6949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8beface5-f359-4367-b79f-bfab7da6b82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:48.0) Gecko/20100101 Firefox/48.0'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_agent.strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d166ec-332e-4343-8367-28a1f4212e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e341548-5a2f-4eb8-81ea-87704d41967d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e93e02-b3e5-4fe6-9894-bbac2f4ba906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a412dc24-0196-4306-b608-94321fb02d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "     Esta es la clase de constructor a la que puede pasar un montón de parámetros.\n",
    "     Estos parámetros se almacenan en las variables de instancia de clase para que el\n",
    "     las funciones de clase pueden acceder a ellas más tarde.\n",
    "    \n",
    "     url_pattern: el patrón de expresiones regulares de las URL web para escapar\n",
    "     pages_to_scrape: cuántas páginas raspar\n",
    "     sleep_interval: el intervalo de tiempo en segundos para retrasar entre solicitudes. Si <0, las solicitudes no se retrasarán.\n",
    "     content_parser: una referencia de función que extraerá la información deseada del contenido raspado.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "     Scrape el contenido de una sola url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        try:\n",
    "            user_agent = get_random_ua()\n",
    "            user_agent = user_agent.strip('\\n')\n",
    "            headers = {'user-agent': user_agent}\n",
    "            print(user_agent)\n",
    "            #r = requests.get('http://books.toscrape.com/catalogue/page-1.html',headers=headers)\n",
    "            response = requests.get(url, headers=headers , timeout=10)\n",
    "            \n",
    "            if response.status_code < 300:\n",
    "                print('request was successful \\n')\n",
    "            elif response.status_code >= 400 and r.status_code < 500:\n",
    "                print('request failed because the resource either does not exist or is forbidden \\n')\n",
    "            else:\n",
    "                print('request failed because the response server encountered an error \\n')\n",
    "                \n",
    "            result = self.content_parser(response.content)\n",
    "            self.output_results(result)\n",
    "            \n",
    "        except requests.exceptions.Timeout:\n",
    "            print ('TIMEOUT')\n",
    "            # timeout error... do something\n",
    "        except requests.exceptions.TooManyRedirects:\n",
    "            print ('MANY REDIRECTS')\n",
    "            # redirect error... do something\n",
    "        except requests.exceptions.SSLError:\n",
    "            print ('SSL ERROR')\n",
    "            # ssl error... do something\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print ('REQUESTS EXCEPTION')\n",
    "            # other unknown errors... do something\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "     Exporte el contenido raspado. En este momento simplemente imprime los resultados.\n",
    "     Pero en el futuro puede exportar los resultados a un archivo de texto o base de datos.\n",
    "     \"\"\"\n",
    "    \n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "     Después de instanciar la clase, llame a esta función para iniciar los trabajos de raspado.\n",
    "     Esta función usa un bucle FOR para llamar a `scrape_url()` para cada url a raspar.\n",
    "     \"\"\"\n",
    "    def kickstart(self):\n",
    "        import time\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "            if self.sleep_interval > 0:\n",
    "                print('\\nSLEEP INTERVAL \\n')\n",
    "                time.sleep(1)\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Esta es una función de analizador personalizado que completará en el desafío.\n",
    "En este momento, simplemente devuelve la cadena que se le pasó. Pero en este laboratorio\n",
    "completarás esta función para que extraiga las comillas.\n",
    "Esta función se pasará a la clase IronhackSpider.\n",
    "\"\"\"\n",
    "\n",
    "def quotes_parser(content):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    sopa_git = BeautifulSoup(content)\n",
    "    bloques = sopa_git.select('li.col-xs-6.col-sm-4.col-md-3.col-lg-3 h3 a')\n",
    "    libros=[]\n",
    "    for item in bloques:\n",
    "        libros.append(item.text)\n",
    "    return libros\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_random_ua():\n",
    "    random_ua = ''\n",
    "    ua_file = 'agents.txt'\n",
    "    try:\n",
    "        with open(ua_file) as f:\n",
    "            lines = f.readlines()\n",
    "        if len(lines) > 0:\n",
    "            prng = np.random.RandomState()\n",
    "            index = prng.permutation(len(lines) - 1)\n",
    "            idx = np.asarray(index, dtype=np.integer)[0]\n",
    "            random_ua = lines[int(idx)]\n",
    "    except Exception as ex:\n",
    "        print('Exception in random_ua')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return random_ua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0af5b8d7-7650-4e48-be8c-98c5677c8420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c0/ffsv0l194g90gxqj1nlsmvdw0000gn/T/ipykernel_22436/4040587833.py:141: DeprecationWarning: Converting `np.integer` or `np.signedinteger` to a dtype is deprecated. The current result is `np.dtype(np.int_)` which is not strictly correct. Note that the result depends on the system. To ensure stable results use may want to use `np.int64` or `np.int32`.\n",
      "  idx = np.asarray(index, dtype=np.integer)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Linux; Android 4.4.2; GT-I9505 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.517 Mobile Safari/537.36\n",
      "request was successful \n",
      "\n",
      "['A Light in the ...', 'Tipping the Velvet', 'Soumission', 'Sharp Objects', 'Sapiens: A Brief History ...', 'The Requiem Red', 'The Dirty Little Secrets ...', 'The Coming Woman: A ...', 'The Boys in the ...', 'The Black Maria', 'Starving Hearts (Triangular Trade ...', \"Shakespeare's Sonnets\", 'Set Me Free', \"Scott Pilgrim's Precious Little ...\", 'Rip it Up and ...', 'Our Band Could Be ...', 'Olio', 'Mesaerion: The Best Science ...', 'Libertarianism for Beginners', \"It's Only the Himalayas\"]\n",
      "\n",
      "SLEEP INTERVAL \n",
      "\n",
      "Mozilla/5.0 (Linux; Android 4.3; GT-I9300 Build/JSS15J) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.136 Mobile Safari/537.36\n",
      "request was successful \n",
      "\n",
      "['In Her Wake', 'How Music Works', 'Foolproof Preserving: A Guide ...', 'Chase Me (Paris Nights ...', 'Black Dust', 'Birdsong: A Story in ...', \"America's Cradle of Quarterbacks: ...\", 'Aladdin and His Wonderful ...', 'Worlds Elsewhere: Journeys Around ...', 'Wall and Piece', 'The Four Agreements: A ...', 'The Five Love Languages: ...', 'The Elephant Tree', 'The Bear and the ...', \"Sophie's World\", 'Penny Maybe', 'Maude (1883-1993):She Grew Up ...', 'In a Dark, Dark ...', 'Behind Closed Doors', \"You can't bury them ...\"]\n",
      "\n",
      "SLEEP INTERVAL \n",
      "\n",
      "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36\n",
      "request was successful \n",
      "\n",
      "['Slow States of Collapse: ...', 'Reasons to Stay Alive', 'Private Paris (Private #10)', '#HigherSelfie: Wake Up Your ...', 'Without Borders (Wanderlove #1)', 'When We Collided', 'We Love You, Charlie ...', 'Untitled Collection: Sabbath Poems ...', 'Unseen City: The Majesty ...', 'Unicorn Tracks', 'Unbound: How Eight Technologies ...', 'Tsubasa: WoRLD CHRoNiCLE 2 ...', 'Throwing Rocks at the ...', 'This One Summer', 'Thirst', 'The Torch Is Passed: ...', 'The Secret of Dreadwillow ...', 'The Pioneer Woman Cooks: ...', 'The Past Never Ends', 'The Natural History of ...']\n",
      "\n",
      "SLEEP INTERVAL \n",
      "\n"
     ]
    }
   ],
   "source": [
    "URL_PATTERN = 'http://books.toscrape.com/catalogue/page-%s.html' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 3 # how many webpages to scrapge\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE,  sleep_interval=1, content_parser=quotes_parser)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c3b1321-25be-4e14-adfb-15cec6f2aa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c0/ffsv0l194g90gxqj1nlsmvdw0000gn/T/ipykernel_23932/4040587833.py:141: DeprecationWarning: Converting `np.integer` or `np.signedinteger` to a dtype is deprecated. The current result is `np.dtype(np.int_)` which is not strictly correct. Note that the result depends on the system. To ensure stable results use may want to use `np.int64` or `np.int32`.\n",
      "  idx = np.asarray(index, dtype=np.integer)[0]\n"
     ]
    }
   ],
   "source": [
    "user_agent = get_random_ua()\n",
    "user_agent = user_agent.strip('\\n')\n",
    "headers = {'user-agent': user_agent}\n",
    "r = requests.get('http://books.toscrape.com/catalogue/page-1.html',headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a447fc2-c73b-4a02-8864-5b8b950f02ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m... World!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    print('Hello ...')\n",
    "    await asyncio.sleep(1)\n",
    "    print('... World!')\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "178e7dfa-8f31-4d8b-8d09-0657f95416a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pygments/formatters/terminal256.py:186: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  self.xterm_colors.append((v, v, v))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Segunda tarea\u001b[39;00m\n\u001b[1;32m     18\u001b[0m loop\u001b[38;5;241m.\u001b[39mcreate_task(mensaje(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMensaje #2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_forever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m loop\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/asyncio/base_events.py:591\u001b[0m, in \u001b[0;36mBaseEventLoop.run_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m\"\"\"Run until stop() is called.\"\"\"\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m--> 591\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_coroutine_origin_tracking(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debug)\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_id \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mget_ident()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/asyncio/base_events.py:583\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_running\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m--> 583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    586\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensaje #2\n",
      "Mensaje #1\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "\"\"\"\n",
    "mensaje: Función que esperara un tiempo determinado, para\n",
    "luego mostrar el texto.\n",
    "\"\"\"\n",
    "async def mensaje(texto, s):\n",
    "    await asyncio.sleep(s)\n",
    "    print(texto)\n",
    "    \n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "# Primera tarea\n",
    "loop.create_task(mensaje(\"Mensaje #1\", 2))\n",
    "\n",
    "\n",
    "# Segunda tarea\n",
    "loop.create_task(mensaje(\"Mensaje #2\", 1))\n",
    "\n",
    "loop.run_forever()\n",
    "loop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23cb6396-5d82-48d3-b99c-93519e868b01",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminuto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Con gather, podemos ejecutar las dos rutinas \u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# simultaneamente\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_seconds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mshow_minute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m loop\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/asyncio/base_events.py:623\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m--> 623\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[1;32m    626\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/asyncio/base_events.py:583\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_running\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m--> 583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    586\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 s\n",
      "1 s\n",
      "2 s\n",
      "3 s\n",
      "4 s\n",
      "5 s\n",
      "6 s\n",
      "7 s\n",
      "8 s\n",
      "9 s\n",
      "10 s\n",
      "11 s\n",
      "12 s\n",
      "13 s\n",
      "14 s\n",
      "15 s\n",
      "16 s\n",
      "17 s\n",
      "18 s\n",
      "19 s\n",
      "20 s\n",
      "21 s\n",
      "22 s\n",
      "23 s\n",
      "24 s\n",
      "25 s\n",
      "26 s\n",
      "27 s\n",
      "28 s\n",
      "29 s\n",
      "30 s\n",
      "31 s\n",
      "32 s\n",
      "33 s\n",
      "34 s\n",
      "35 s\n",
      "36 s\n",
      "37 s\n",
      "38 s\n",
      "39 s\n",
      "40 s\n",
      "41 s\n",
      "42 s\n",
      "43 s\n",
      "44 s\n",
      "45 s\n",
      "46 s\n",
      "47 s\n",
      "48 s\n",
      "49 s\n",
      "50 s\n",
      "51 s\n",
      "52 s\n",
      "53 s\n",
      "54 s\n",
      "55 s\n",
      "56 s\n",
      "57 s\n",
      "58 s\n",
      "59 s\n",
      "1 minuto\n",
      "0 s\n",
      "1 s\n",
      "2 s\n",
      "3 s\n",
      "4 s\n",
      "5 s\n",
      "6 s\n",
      "7 s\n",
      "8 s\n",
      "9 s\n",
      "10 s\n",
      "11 s\n",
      "12 s\n",
      "13 s\n",
      "14 s\n",
      "15 s\n",
      "16 s\n",
      "17 s\n",
      "18 s\n",
      "19 s\n",
      "20 s\n",
      "21 s\n",
      "22 s\n",
      "23 s\n",
      "24 s\n",
      "25 s\n",
      "26 s\n",
      "27 s\n",
      "28 s\n",
      "29 s\n",
      "30 s\n",
      "31 s\n",
      "32 s\n",
      "33 s\n",
      "34 s\n",
      "35 s\n",
      "36 s\n",
      "37 s\n",
      "38 s\n",
      "39 s\n",
      "40 s\n",
      "41 s\n",
      "42 s\n",
      "43 s\n",
      "44 s\n",
      "45 s\n",
      "46 s\n",
      "47 s\n",
      "48 s\n",
      "49 s\n",
      "50 s\n",
      "51 s\n",
      "52 s\n",
      "53 s\n",
      "54 s\n",
      "55 s\n",
      "56 s\n",
      "57 s\n",
      "58 s\n",
      "59 s\n",
      "2 minuto\n",
      "0 s\n",
      "1 s\n",
      "2 s\n",
      "3 s\n",
      "4 s\n",
      "5 s\n",
      "6 s\n",
      "7 s\n",
      "8 s\n",
      "9 s\n",
      "10 s\n",
      "11 s\n",
      "12 s\n",
      "13 s\n",
      "14 s\n",
      "15 s\n",
      "16 s\n",
      "17 s\n",
      "18 s\n",
      "19 s\n",
      "20 s\n",
      "21 s\n",
      "22 s\n",
      "23 s\n",
      "24 s\n",
      "25 s\n",
      "26 s\n",
      "27 s\n",
      "28 s\n",
      "29 s\n",
      "30 s\n",
      "31 s\n",
      "32 s\n",
      "33 s\n",
      "34 s\n",
      "35 s\n",
      "36 s\n",
      "37 s\n",
      "38 s\n",
      "39 s\n",
      "40 s\n",
      "41 s\n",
      "42 s\n",
      "43 s\n",
      "44 s\n",
      "45 s\n",
      "46 s\n",
      "47 s\n",
      "48 s\n",
      "49 s\n",
      "50 s\n",
      "51 s\n",
      "52 s\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "# definimos la función\n",
    "async def show_seconds():\n",
    "    \"Segundos\"\n",
    "    while True:\n",
    "        for i in range(60):\n",
    "            print(i, 's')\n",
    "            await asyncio.sleep(1)\n",
    "\n",
    "\n",
    "async def show_minute():\n",
    "    for i in range(1, 10):\n",
    "        await asyncio.sleep(60)\n",
    "        print(i, 'minuto')\n",
    "\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(\n",
    "    # Con gather, podemos ejecutar las dos rutinas \n",
    "    # simultaneamente\n",
    "    asyncio.gather(show_seconds(),\n",
    "                   show_minute())\n",
    ")\n",
    "loop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d904866-5533-432f-b4e4-97c0057b0e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
